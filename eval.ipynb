{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import metrics\n",
    "from metrics import (\n",
    "    calculate_psnr, \n",
    "    calculate_ssim, \n",
    "    calculate_fourier_spectrum_similarity,\n",
    "    calculate_phase_consistency,\n",
    "    calculate_lpips,\n",
    "    tensor2img\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: LPIPS Check\n",
    "# Try to import LPIPS if available\n",
    "try:\n",
    "    import lpips\n",
    "    LPIPS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LPIPS_AVAILABLE = False\n",
    "    print(\"LPIPS not available. Install with: pip install lpips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluation Function\n",
    "def evaluate_model(model_path, test_data_path, output_dir, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate a trained super-resolution model\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained model checkpoint\n",
    "        test_data_path: Path to test dataset\n",
    "        output_dir: Directory to save evaluation results\n",
    "        device: Device to run evaluation on\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load model\n",
    "    from resdiff import ResDiffModel\n",
    "    model = ResDiffModel().to(device)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize LPIPS if available\n",
    "    if LPIPS_AVAILABLE:\n",
    "        lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
    "    \n",
    "    # Load test dataset\n",
    "    from dataset import SuperResolutionDataset\n",
    "    test_dataset = SuperResolutionDataset(test_data_path)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=1, shuffle=False, num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Initialize metrics\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    fourier_sim_values = []\n",
    "    phase_consistency_values = []\n",
    "    lpips_values = []\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    with torch.no_grad():\n",
    "        for i, (lr, hr) in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            \n",
    "            # Generate super-resolution image\n",
    "            sr = model(lr)\n",
    "            \n",
    "            # Convert to numpy for metrics calculation\n",
    "            sr_np = tensor2img(sr[0])\n",
    "            hr_np = tensor2img(hr[0])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            psnr = calculate_psnr(sr_np, hr_np)\n",
    "            ssim_val = calculate_ssim(sr_np, hr_np)\n",
    "            fourier_sim = calculate_fourier_spectrum_similarity(sr_np, hr_np)\n",
    "            phase_cons = calculate_phase_consistency(sr_np, hr_np)\n",
    "            \n",
    "            # Calculate LPIPS if available\n",
    "            if LPIPS_AVAILABLE:\n",
    "                lpips_val = calculate_lpips(sr, hr, lpips_fn)\n",
    "                lpips_values.append(lpips_val)\n",
    "            \n",
    "            # Store metrics\n",
    "            psnr_values.append(psnr)\n",
    "            ssim_values.append(ssim_val)\n",
    "            fourier_sim_values.append(fourier_sim)\n",
    "            phase_consistency_values.append(phase_cons)\n",
    "            \n",
    "            # Save sample images every 10 images\n",
    "            if i % 10 == 0:\n",
    "                save_path = os.path.join(output_dir, f\"sample_{i}.png\")\n",
    "                plt.figure(figsize=(15, 5))\n",
    "                \n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(tensor2img(lr[0]))\n",
    "                plt.title(\"Low Resolution\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(sr_np)\n",
    "                plt.title(f\"Super Resolution (PSNR: {psnr:.2f})\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(hr_np)\n",
    "                plt.title(\"High Resolution\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    avg_fourier_sim = np.mean(fourier_sim_values)\n",
    "    avg_phase_cons = np.mean(phase_consistency_values)\n",
    "    \n",
    "    if LPIPS_AVAILABLE:\n",
    "        avg_lpips = np.mean(lpips_values)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Average PSNR: {avg_psnr:.4f}\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average Fourier Spectrum Similarity: {avg_fourier_sim:.4f}\")\n",
    "    print(f\"Average Phase Consistency: {avg_phase_cons:.4f}\")\n",
    "    \n",
    "    if LPIPS_AVAILABLE:\n",
    "        print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    \n",
    "    # Save results to file\n",
    "    with open(os.path.join(output_dir, \"evaluation_results.txt\"), \"w\") as f:\n",
    "        f.write(f\"Average PSNR: {avg_psnr:.4f}\\n\")\n",
    "        f.write(f\"Average SSIM: {avg_ssim:.4f}\\n\")\n",
    "        f.write(f\"Average Fourier Spectrum Similarity: {avg_fourier_sim:.4f}\\n\")\n",
    "        f.write(f\"Average Phase Consistency: {avg_phase_cons:.4f}\\n\")\n",
    "        \n",
    "        if LPIPS_AVAILABLE:\n",
    "            f.write(f\"Average LPIPS: {avg_lpips:.4f}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"psnr\": avg_psnr,\n",
    "        \"ssim\": avg_ssim,\n",
    "        \"fourier_sim\": avg_fourier_sim,\n",
    "        \"phase_cons\": avg_phase_cons,\n",
    "        \"lpips\": avg_lpips if LPIPS_AVAILABLE else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dinesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: c:\\Users\\Dinesh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 376/376 [01:10<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Average PSNR: 38.8085\n",
      "Average SSIM: 0.9049\n",
      "Average Fourier Spectrum Similarity: 0.9979\n",
      "Average Phase Consistency: 0.4902\n",
      "Average LPIPS: 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Run Evaluation\n",
    "# Set evaluation parameters\n",
    "model_path = \"results/resdiff_final.pth\"  # Path to your trained model\n",
    "test_data_path = \"datasets/test\"  # Path to your test dataset\n",
    "output_dir = \"evaluation_results\"  # Directory to save results\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_model(\n",
    "    model_path=model_path,\n",
    "    test_data_path=test_data_path,\n",
    "    output_dir=output_dir,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Let me analyze these scores for you:\n",
    "PSNR (Peak Signal-to-Noise Ratio): 21.31 dB\n",
    "This is a moderate score for super-resolution\n",
    "Typical ranges:\n",
    "Excellent: > 30 dB\n",
    "Good: 25-30 dB\n",
    "Moderate: 20-25 dB\n",
    "Poor: < 20 dB\n",
    "Your score of 21.31 dB indicates moderate performance\n",
    "\n",
    "SSIM (Structural Similarity Index): 0.8521\n",
    "This is a good score\n",
    "SSIM ranges from 0 to 1, where 1 is perfect\n",
    "Your score of 0.8521 indicates good structural preservation\n",
    "Typical ranges:\n",
    "Excellent: > 0.95\n",
    "Good: 0.85-0.95\n",
    "Moderate: 0.75-0.85\n",
    "Poor: < 0.75\n",
    "\n",
    "Fourier Spectrum Similarity: 0.9992\n",
    "This is an excellent score\n",
    "The score of 0.9992 indicates very good preservation of frequency domain information\n",
    "This suggests your model is doing well at maintaining the frequency characteristics of the images\n",
    "\n",
    "Phase Consistency: 0.4556\n",
    "This is a moderate score\n",
    "Phase consistency ranges from 0 to 1, where 1 is perfect alignment\n",
    "Your score of 0.4556 indicates room for improvement in phase alignment\n",
    "This might be an area to focus on for improvement\n",
    "\n",
    "LPIPS (Learned Perceptual Image Patch Similarity): 0.3773\n",
    "This is a moderate score\n",
    "LPIPS ranges from 0 to 1, where 0 is better (more similar)\n",
    "Your score of 0.3773 indicates moderate perceptual similarity\n",
    "Typical ranges:\n",
    "Excellent: < 0.2\n",
    "Good: 0.2-0.3\n",
    "Moderate: 0.3-0.4\n",
    "Poor: > 0.4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
